{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a54e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b7bef2",
   "metadata": {},
   "source": [
    "## Parsing Summary files of GPT4o experiments to consolidate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f38fef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\n",
    "    \"benchmark_name\",\n",
    "    \"workflow\",\n",
    "    \"model\",\n",
    "    \"num_questions\",\n",
    "    \"num_correct\",\n",
    "    \"accuracy\",\n",
    "    \"conf_1_accuracy\",\n",
    "    \"conf_2_accuracy\",\n",
    "    \"conf_3_accuracy\",\n",
    "    \"conf_4_accuracy\",\n",
    "    \"conf_5_accuracy\"\n",
    "]\n",
    "\n",
    "# Prepare CSV rows\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56038d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary stats written to summary_stats_mas.csv\n"
     ]
    }
   ],
   "source": [
    "##ZEROSHOT PARSING\n",
    "folder_path = \"../../out/gpt4o/zeroshot\" \n",
    "for filename in os.listdir(folder_path):\n",
    "    if (\"SUMMARY_\") in filename and filename.endswith(\".txt\"):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        with open(filepath, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            # Extract benchmark name\n",
    "            benchmark_name = filename.replace(\"SUMMARY_\", \"\").replace(\".txt\", \"\")\n",
    "\n",
    "            # Extract main stats\n",
    "            num_questions = int(re.search(r\"Total questions:\\s*(\\d+)\", content).group(1))\n",
    "            num_correct = int(re.search(r\"Correct:\\s*(\\d+)\", content).group(1))\n",
    "            accuracy = float(re.search(r\"Overall Accuracy:\\s*([\\d.]+)%\", content).group(1))\n",
    "\n",
    "            # Initialize confidence level accuracy\n",
    "            conf_accuracy = {str(i): '' for i in range(1, 6)}\n",
    "\n",
    "            # Find all confidence level accuracies\n",
    "            for match in re.finditer(r\"(\\d):\\s*([\\d.]+)%\", content):\n",
    "                level, value = match.groups()\n",
    "                conf_accuracy[level] = float(value)\n",
    "\n",
    "            row = [\n",
    "                benchmark_name,\n",
    "                \"zeroshot\",\n",
    "                \"gpt4o\",\n",
    "                num_questions,\n",
    "                num_correct,\n",
    "                accuracy,\n",
    "                conf_accuracy['1'],\n",
    "                conf_accuracy['2'],\n",
    "                conf_accuracy['3'],  # May remain blank if missing\n",
    "                conf_accuracy['4'],\n",
    "                conf_accuracy['5']\n",
    "            ]\n",
    "            rows.append(row)\n",
    "\n",
    "# Write to CSV\n",
    "with open(output_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Summary stats written to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b888a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "##EVALOPTIM PARSING\n",
    "folder_path = \"../../out/gpt4o/evaloptim\" \n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\"SUMMARY.txt\"):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        with open(filepath, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            # Extract benchmark name\n",
    "            benchmark_name = 'evaloptim_gpt4o_' + filename.replace(\"_SUMMARY.txt\", \"\")\n",
    "\n",
    "            # Extract main stats\n",
    "            num_questions = int(re.search(r\"Total questions:\\s*(\\d+)\", content).group(1))\n",
    "            num_correct = int(re.search(r\"Correct:\\s*(\\d+)\", content).group(1))\n",
    "            accuracy = float(re.search(r\"Overall Accuracy:\\s*([\\d.]+)%\", content).group(1))\n",
    "\n",
    "            # Initialize confidence level accuracy\n",
    "            conf_accuracy = {str(i): '' for i in range(1, 6)}\n",
    "\n",
    "            # Find all confidence level accuracies\n",
    "            for match in re.finditer(r\"(\\d):\\s*([\\d.]+)%\", content):\n",
    "                level, value = match.groups()\n",
    "                conf_accuracy[level] = float(value)\n",
    "\n",
    "            row = [\n",
    "                benchmark_name,\n",
    "                'evaloptim',\n",
    "                'gpt4o',\n",
    "                num_questions,\n",
    "                num_correct,\n",
    "                accuracy,\n",
    "                conf_accuracy['1'],\n",
    "                conf_accuracy['2'],\n",
    "                conf_accuracy['3'],  # May remain blank if missing\n",
    "                conf_accuracy['4'],\n",
    "                conf_accuracy['5']\n",
    "            ]\n",
    "            rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##MAS PARSING\n",
    "folder_path = \"../../out/gpt4o/mas\" \n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\"SUMMARY.txt\"):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        with open(filepath, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            # Extract benchmark name\n",
    "            benchmark_name = filename.replace(\"_SUMMARY.txt\", \"\")\n",
    "\n",
    "            # Extract main stats\n",
    "            num_questions = int(re.search(r\"Total questions:\\s*(\\d+)\", content).group(1))\n",
    "            num_correct = int(re.search(r\"Correct:\\s*(\\d+)\", content).group(1))\n",
    "            accuracy = float(re.search(r\"Overall Accuracy:\\s*([\\d.]+)%\", content).group(1))\n",
    "\n",
    "            # Initialize confidence level accuracy\n",
    "            conf_accuracy = {str(i): '' for i in range(1, 6)}\n",
    "\n",
    "            # Find all confidence level accuracies\n",
    "            for match in re.finditer(r\"(\\d):\\s*([\\d.]+)%\", content):\n",
    "                level, value = match.groups()\n",
    "                conf_accuracy[level] = float(value)\n",
    "\n",
    "            row = [\n",
    "                benchmark_name,\n",
    "                'mas',\n",
    "                'gpt4o',\n",
    "                'ethics',\n",
    "                num_questions,\n",
    "                num_correct,\n",
    "                accuracy,\n",
    "                conf_accuracy['1'],\n",
    "                conf_accuracy['2'],\n",
    "                conf_accuracy['3'],  # May remain blank if missing\n",
    "                conf_accuracy['4'],\n",
    "                conf_accuracy['5']\n",
    "            ]\n",
    "            rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbbda2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary stats written to summary_stats_gpt4o.csv\n"
     ]
    }
   ],
   "source": [
    "output_csv = \"summary_stats_gpt4o.csv\"\n",
    "# Write to CSV\n",
    "with open(output_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Summary stats written to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd23d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metamedqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
